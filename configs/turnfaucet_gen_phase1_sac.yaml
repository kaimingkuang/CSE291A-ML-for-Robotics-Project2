trial_name: turnfaucet_gen_phase1_sac
log_dir: logs

env:
    name: TurnFaucet-v2
    # number of parallel envs
    n_env_procs: 32
    # observation mode
    obs_mode: "state"
    # control mode/action mode
    act_mode: pd_ee_delta_pose
    seed: 42
    model_ids: [
        5000,
        5001,
        5002,
        5004,
        5005,
        5006,
        5007,
        5010,
        5011,
        5012,
        5014,
        5015,
        5016,
        5018,
        5020,
        5021,
        5023,
        5024,
        5025,
        5027,
        5028,
        5029,
        5030,
        5033,
        5034,
        5035,
        5037,
        5038,
        5039,
        5040,
        5041,
        5043,
        5044,
        5045,
        5046,
        5047,
        5048,
        5049,
        5050,
        5051,
        5052,
        5053,
        5055,
        5056,
        5057,
        5058,
        5060,
        5061,
        5062,
        5063,
        5064,
        5065,
        5067,
        5068,
        5069,
        5070,
        5072,
        5073,
        5075,
        5076
    ]

train:
    # max number of steps in one training episode
    max_eps_steps: 200
    # total number of training steps
    total_steps: 25000000
    # number of steps to run before each network evaluation
    rollout_steps: 5000
    # batch size in each update
    batch_size: 256
    # reward discounting factor
    gamma: 0.99
    lr: 0.0003

model_name: SAC
net_arch: [256, 256]
model_kwargs:
    verbose: 1
    # inverse of reward scale in SAC paper
    # larger ent_coef means stronger exploration, auto means learnable scale
    ent_coef: auto

eval:
    # evaluation frequency, measured by the number of network updates
    eval_freq: 50
    # number of episodes to run in each evaluation
    n_eval_episodes: 10
    n_final_eval_episodes: 100
